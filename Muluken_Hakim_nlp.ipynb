{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuleHakim/Language-Model/blob/main/Muluken_Hakim_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7y-WD9EU890"
      },
      "source": [
        "# 1.  N-gram language model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGcnA3L4Gkxa"
      },
      "source": [
        "## This code reads text from 'GPAC.txt', removes specified punctuation, and saves the cleaned text to 'tokenized.txt'.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ETDawzlJNaL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2550790-3ae2-44e2-e1bc-6602532d97f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized text saved to tokenized.txt\n"
          ]
        }
      ],
      "source": [
        "# Set of punctuation characters to be removed\n",
        "punctuation_to_remove = '-.፤፣/:፡;<=>!\"?@[\\\\]^#$%&\\'()*+,_`{|}~'\n",
        "\n",
        "# Read the content of GPAC.txt with explicit encoding and handle decoding errors\n",
        "with open('GPAC.txt', 'r', encoding='utf-8', errors='replace') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Remove specified punctuation marks\n",
        "tokenized_txt = ''.join(['' if char in punctuation_to_remove else char for char in text])\n",
        "\n",
        "# Create a new filename for the tokenized text\n",
        "output_filename = 'tokenized.txt'\n",
        "\n",
        "# Write the tokenized text to the new file\n",
        "with open(output_filename, 'w', encoding='utf-8') as file:\n",
        "    file.write(tokenized_txt)\n",
        "\n",
        "print(f\"Tokenized text saved to {output_filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_K-8i7lLE_X"
      },
      "source": [
        " ## 1.1 Create n-grams for n=1, 2, 3, 4. You can show sample prints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRdiER6hKKCw"
      },
      "outputs": [],
      "source": [
        "def generate_N_grams(text,ngram):\n",
        "  words=[word for word in text.split()]\n",
        "  temp=zip(*[words[i:] for i in range(0,ngram)])\n",
        "  grams=[' '.join(ngram) for ngram in temp]\n",
        "  return grams\n",
        "\n",
        "# Read the text from the file\n",
        "text = open(\"tokenized.txt\", \"r\", encoding='utf-8', errors='replace').read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlNJXJMsUUnP"
      },
      "source": [
        "## Create Unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCn8pUxsUFNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4fbf542-9592-4c3e-809a-b338c8fcc57e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample unigrams: ['ምን', 'መሰላችሁ', 'አንባቢያን', 'ኢትዮጵያ', 'በተደጋጋሚ', 'ጥሪው', 'ደርሷት', 'ልትታደመው', 'ያልቻለችው', 'የአለም']\n"
          ]
        }
      ],
      "source": [
        "# Create unigrams\n",
        "unigrams = generate_N_grams(text, 1)\n",
        "print(\"Sample unigrams:\", unigrams[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lMrMeUcUXXw"
      },
      "source": [
        "## Create Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxtSRMGCUHRx",
        "outputId": "dbe2d077-52bc-46c4-9f86-dad202ba4772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample bigrams: ['ምን መሰላችሁ', 'መሰላችሁ አንባቢያን', 'አንባቢያን ኢትዮጵያ', 'ኢትዮጵያ በተደጋጋሚ', 'በተደጋጋሚ ጥሪው', 'ጥሪው ደርሷት', 'ደርሷት ልትታደመው', 'ልትታደመው ያልቻለችው', 'ያልቻለችው የአለም', 'የአለም የእግር']\n"
          ]
        }
      ],
      "source": [
        "# Create bigrams\n",
        "bigrams = generate_N_grams(text, 2)\n",
        "print(\"Sample bigrams:\", bigrams[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcOpf_v8UbOa"
      },
      "source": [
        "## Create Trigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxaCdLPbUJPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13e491ee-6dd0-4d90-d241-b1fb97594713"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample trigrams: ['ምን መሰላችሁ አንባቢያን', 'መሰላችሁ አንባቢያን ኢትዮጵያ', 'አንባቢያን ኢትዮጵያ በተደጋጋሚ', 'ኢትዮጵያ በተደጋጋሚ ጥሪው', 'በተደጋጋሚ ጥሪው ደርሷት', 'ጥሪው ደርሷት ልትታደመው', 'ደርሷት ልትታደመው ያልቻለችው', 'ልትታደመው ያልቻለችው የአለም', 'ያልቻለችው የአለም የእግር', 'የአለም የእግር ኳስ']\n"
          ]
        }
      ],
      "source": [
        "# Create trigrams\n",
        "trigrams = generate_N_grams(text, 3)\n",
        "print(\"Sample trigrams:\", trigrams[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ELgOzrrUe_p"
      },
      "source": [
        "## Create Quadrigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQXEFj1EUKvu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f50f829d-c876-43e2-a9d1-7a9c1aa4d3e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample quadrigrams: ['ምን መሰላችሁ አንባቢያን ኢትዮጵያ', 'መሰላችሁ አንባቢያን ኢትዮጵያ በተደጋጋሚ', 'አንባቢያን ኢትዮጵያ በተደጋጋሚ ጥሪው', 'ኢትዮጵያ በተደጋጋሚ ጥሪው ደርሷት', 'በተደጋጋሚ ጥሪው ደርሷት ልትታደመው', 'ጥሪው ደርሷት ልትታደመው ያልቻለችው', 'ደርሷት ልትታደመው ያልቻለችው የአለም', 'ልትታደመው ያልቻለችው የአለም የእግር', 'ያልቻለችው የአለም የእግር ኳስ', 'የአለም የእግር ኳስ ዋ']\n"
          ]
        }
      ],
      "source": [
        "# Create quadrigrams\n",
        "quadgrams = generate_N_grams(text, 4)\n",
        "print(\"Sample quadrigrams:\", quadgrams[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1kjSC1CMjPZ"
      },
      "source": [
        "## 1.2 Calculate probabilities of n-grams and find the top 10 most likely n-grams for all n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I78q3qLILqAI"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def calculate_ngram_probabilities(ngrams):\n",
        "    ngram_counts = Counter(ngrams)\n",
        "    total_ngrams = len(ngrams)\n",
        "    probabilities = {ngram: count / total_ngrams for ngram, count in ngram_counts.items()}\n",
        "    return probabilities\n",
        "\n",
        "# Calculate probabilities for each n-gram\n",
        "uni_probabilities = calculate_ngram_probabilities(unigrams)\n",
        "bi_probabilities = calculate_ngram_probabilities(bigrams)\n",
        "tri_probabilities = calculate_ngram_probabilities(trigrams)\n",
        "quad_probabilities = calculate_ngram_probabilities(quadgrams)\n",
        "\n",
        "# Find the top 10 most likely n-grams for each n\n",
        "top_10_unigrams = sorted(uni_probabilities.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "top_10_bigrams = sorted(bi_probabilities.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "top_10_trigrams = sorted(tri_probabilities.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "top_10_quadgrams = sorted(quad_probabilities.items(), key=lambda x: x[1], reverse=True)[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsKDYnx8Scqb"
      },
      "source": [
        "### Top 10 Unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ewe4Cg-bSZrO",
        "outputId": "161447be-2161-4425-c296-cf6832589554"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 Unigrams:\n",
            "\n",
            "ነው: 0.017153159973555022\n",
            "ላይ: 0.009318220971369312\n",
            "ግን: 0.004733745135350133\n",
            "ውስጥ: 0.004593625442808291\n",
            "ወደ: 0.004484875830686265\n",
            "እና: 0.004378217557258893\n",
            "ነበር: 0.004088305730712433\n",
            "ጋር: 0.0036648096450449257\n",
            "ነገር: 0.0036593198809714584\n",
            "ጊዜ: 0.003102239536182904\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nTop 10 Unigrams:\\n\")\n",
        "for ngram, probability in top_10_unigrams:\n",
        "    print(f\"{ngram}: {probability}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMQkvYHSSo8t"
      },
      "source": [
        "### Top 10 Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPWqXGwANV-x",
        "outputId": "b53b3807-2e76-4373-b702-d6e8b1ab91cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 Bigrams:\n",
            "\n",
            "ዓ ም: 0.0010854050662693123\n",
            "ነገር ግን: 0.0006276631898151779\n",
            "ማለት ነው: 0.0005267560714192351\n",
            "ብቻ ሳይሆን: 0.00044153399733354244\n",
            "ብቻ ነው: 0.0003814079941442501\n",
            "አዲስ አበባ: 0.0003508221577392623\n",
            "በአዲስ አበባ: 0.0002679528403001072\n",
            "ምን ያህል: 0.0002661229184639113\n",
            "ላይ ነው: 0.00023318432541238594\n",
            "እኮ ነው: 0.0002227276292055525\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"\\nTop 10 Bigrams:\\n\")\n",
        "for ngram, probability in top_10_bigrams:\n",
        "    print(f\"{ngram}: {probability}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOqWU3YVSr8Z"
      },
      "source": [
        "### Top 10 Trigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T3b3MbyNXtd",
        "outputId": "20fa4baf-4339-40c7-a0e0-47beb886eed5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 Trigrams:\n",
            "\n",
            "እ ኤ አ: 0.00018220797903640995\n",
            "ቂ ቂ ቂ: 7.55496498443651e-05\n",
            "2006 ዓ ም: 6.483153343045863e-05\n",
            "ነው ነገር ግን: 6.430869848343881e-05\n",
            "የኢትዮጵያ ብሄራዊ ቡድን: 6.378586353641898e-05\n",
            "ወደ አዲስ አበባ: 6.0648853854300015e-05\n",
            "ቀን 2006 ዓ: 5.3067747122512517e-05\n",
            "ዓ ም ጀምሮ: 5.254491217549269e-05\n",
            "ጨዋታ ያነሳው የለ: 5.176065975496295e-05\n",
            "ጨዋታን ጨዋታ ያነሳው: 5.123782480794312e-05\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nTop 10 Trigrams:\\n\")\n",
        "for ngram, probability in top_10_trigrams:\n",
        "    print(f\"{ngram}: {probability}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWlIMhYCSumP"
      },
      "source": [
        "### Top 10 Quadgram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSbTrf5GNazg",
        "outputId": "f1d7c74a-dca5-418f-d3c2-9e1677b50025"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 Quadrigrams:\n",
            "\n",
            "ቀን 2006 ዓ ም: 5.2806343453503494e-05\n",
            "ጨዋታን ጨዋታ ያነሳው የለ: 5.123783820240933e-05\n",
            "ቀን 2005 ዓ ም: 3.764412602625992e-05\n",
            "እንግዲህ ጨዋታን ጨዋታ ያነሳው: 3.712129094256186e-05\n",
            "የጽንስና ማህጸን ሐኪሞች ማህበር: 3.2938610272977425e-05\n",
            "ቀን 2004 ዓ ም: 3.241577518927937e-05\n",
            "ቀን 2007 ዓ ም: 2.6403171726751747e-05\n",
            "የኢትዮጵያ የጽንስና ማህጸን ሐኪሞች: 1.6469305136488713e-05\n",
            "ምን ቢል ጥሩ ነው: 1.3855129717998442e-05\n",
            "ጠቅላይ ሚኒስትር መለስ ዜናዊ: 1.2548042008753305e-05\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nTop 10 Quadrigrams:\\n\")\n",
        "for ngram, probability in top_10_quadgrams:\n",
        "    print(f\"{ngram}: {probability}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo7nhcv_QomK"
      },
      "source": [
        "## 1.3 What is the probability of the sentence. \"ኢትዮጵያ ታሪካዊ ሀገር ናት \". You can also try more sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDrUs5ROM4PD",
        "outputId": "b5e03e4d-6449-4756-cbaf-dc584b776cac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of the 'መሠረታዊ አሐዶች ሆነው' : 0.00019998436217913052\n",
            "Probability of the 'ከአብዮቱ ዘመን በኋላ የተወለደ ቢሆን ነው ስሙን ሳሚ ብለው የሰየሙት' : 0.07032350118631571\n",
            "Probability of the 'ኢትዮጵያ ታሪካዊ ሀገር ናት' : 1.048616396880345e-08\n",
            "Probability of the 'በየጊዜው ከሚደረገው ቅነሳ' : 0.00014404106008802928\n"
          ]
        }
      ],
      "source": [
        "# find the probablity\n",
        "from collections import Counter\n",
        "unigramCounter = Counter(unigrams)\n",
        "bigramCounter = Counter(bigrams)\n",
        "unigramsTotal = len(unigrams)\n",
        "bigramsTotal = len(bigrams)\n",
        "\n",
        "def probablity(word, prevWord=''):\n",
        "  if prevWord == '':\n",
        "    return unigramCounter[word] / unigramsTotal\n",
        "\n",
        "  wordCount = bigramCounter[word]\n",
        "  prevWordCount = unigramCounter[prevWord]\n",
        "\n",
        "  return wordCount+1 / (prevWordCount+len(bigramCounter))\n",
        "\n",
        "def findProbablity(sentence):\n",
        "  words = sentence.split()\n",
        "\n",
        "  i = 0\n",
        "  sentenceProbablity = probablity(words[i])\n",
        "  while i+1 < len(words):\n",
        "    sentenceProbablity *= (probablity(' '.join(words[i:i+2]), words[i]))\n",
        "    i += 1\n",
        "\n",
        "  return sentenceProbablity\n",
        "\n",
        "\n",
        "# Example usage\n",
        "sentences = [\"መሠረታዊ አሐዶች ሆነው\",\n",
        "             \"ከአብዮቱ ዘመን በኋላ የተወለደ ቢሆን ነው ስሙን ሳሚ ብለው የሰየሙት\",\n",
        "             \"ኢትዮጵያ ታሪካዊ ሀገር ናት\",\n",
        "             \"በየጊዜው ከሚደረገው ቅነሳq\"\n",
        "            ]\n",
        "for sentence in sentences:\n",
        "  print(f\"Probability of the '{sentence}' : {findProbablity(sentence)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz_cho0TRaWV"
      },
      "source": [
        "## 1.4 Generate random sentences using n-grams; explain what happens as n increases, based on your output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5R80_cTkMUCp"
      },
      "outputs": [],
      "source": [
        "\n",
        "import random\n",
        "\n",
        "def generate_random_sentence(ngrams, n):\n",
        "    sentence = []\n",
        "    start_ngram = random.choice(ngrams)\n",
        "    sentence.extend(start_ngram.split())\n",
        "\n",
        "    while len(sentence) < 30:  # Limit the sentence length to avoid infinite loops\n",
        "        if n == 1:\n",
        "          current_prefix = \"\"\n",
        "        else:\n",
        "          current_prefix = \" \".join(sentence[-(n-1):])\n",
        "        possible_next_ngrams = [ngram for ngram in ngrams if ngram.startswith(current_prefix)]\n",
        "        if not possible_next_ngrams:\n",
        "            break\n",
        "\n",
        "        next_ngram = random.choice(possible_next_ngrams)\n",
        "        sentence.append(next_ngram.split()[-1])\n",
        "\n",
        "    return \" \".join(sentence)\n",
        "\n",
        "# Generate random sentences for each n-gram\n",
        "random_sentence_unigrams = generate_random_sentence(unigrams, 1)\n",
        "random_sentence_bigrams = generate_random_sentence(bigrams, 2)\n",
        "random_sentence_trigrams = generate_random_sentence(trigrams, 3)\n",
        "random_sentence_quadgrams = generate_random_sentence(quadgrams, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5Jqg5CPTJpU"
      },
      "source": [
        "## Random Sentence for Unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEGlDT5HTGFo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6cf4b9d-c989-42ec-e5bb-92ab244bb514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Sentence (Unigrams): አዘጋጅ ወረዱ ላይ ቁጭት ምናምን ያስቀመጣት የምድብ 60 እንቀመጣለን የቦርዱ የወለዱኝ በአዲስ በሚገባ ምርጫ ምክንያቶች በዚህ ቤት በነፍሰ አምፕሊፋየር በአለምአቀፍ በኩል ይላካል አጋሰስና አንድ አስቸጋሪ አይታለፍም ኮሚሽን ገነትን ሲል ነው\n"
          ]
        }
      ],
      "source": [
        "# Print the results\n",
        "print(\"Random Sentence (Unigrams):\", random_sentence_unigrams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD4skE3iTRmf"
      },
      "source": [
        "## Random Sentence for Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbNGD8K-TWJx",
        "outputId": "9807244e-88d3-455a-9fbb-afad5c151591"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Sentence (Bigrams): ለሞቱት የህሊና ሚና ለተጫወቱትና ለራያ ቢራ በቅርብ ለማወቅ ተችሏል በተመሳሳይ መልኩ የሙዚቃ መሳሪያዎችን ሳያስወግዱ ሌሎች ፈተናዎች መካከል የጨረታ ዋጋው የማይቀመሰው አሜሪካ ሴቶች ቀደም ብለው ነበር ኪሳራውን አስልቼ ነው ብለዋል ዶር\n"
          ]
        }
      ],
      "source": [
        "print(\"Random Sentence (Bigrams):\", random_sentence_bigrams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXswXiIbTch8"
      },
      "source": [
        "## Random Sentence for Trigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrdDJ8TMTYOQ",
        "outputId": "345ae30d-4621-431f-aba2-1ef906d8bd4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Sentence (Trigrams): የወጡት በሌላ ሰው ሃሳብና መርህ ለመጥቀስ ፈልጎ ይሆን አብዛኛው ሰው የስፔን ነው የተባለውን ቃል ቀዳሚ አድርጐ በሱ መሠረትነት ቀዳሚሃ ለፍቅር ሕይወት ንጉሥ ወሀገር ተከታይ መሆኑን በማወቅ ህዝብና ህዝብ በሰላም እንዲኖር\n"
          ]
        }
      ],
      "source": [
        "print(\"Random Sentence (Trigrams):\", random_sentence_trigrams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw56MoVdTdZF"
      },
      "source": [
        "## Random Sentence for Quadrigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiFBB5nTTZ18",
        "outputId": "4e57b0a4-9c0d-49ab-cfd9-2c83a4679c9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Sentence (Quadgrams): የሚመደበውመ በጀቱ አንድ ብር ለአንድ እናት በሚል ከህብረተሰቡ የሚዋጣ ብር አለ ያ ገንዘብ እንዴት መውጣት እንዳለበት በኮሚቴ ተነጋግረን የሌለ ነገር ማለትም ሽንኩርቱም በርበሬውም ሁሉም እስከ ጤፍ ድረስ መገዛት ያለበት ነገር\n"
          ]
        }
      ],
      "source": [
        "print(\"Random Sentence (Quadgrams):\", random_sentence_quadgrams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FIIb4jzWAvn"
      },
      "source": [
        "### As n increases, the generated sentences tend to be more coherent and contextually relevant. However, with a higher value of n, the model becomes more constrained by the specific sequences observed in the training data, which might lead to sentences that sound more repetitive or less diverse. It's a trade-off between coherence and diversity as you adjust the value of n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XrLs92jR16_"
      },
      "source": [
        "## 2 Evaluate these Language Models Using Intrinsic Evaluation Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUQSHy2qk-8K",
        "outputId": "9164a99f-a7e5-4012-ce4b-36d335cf5a68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity for 1-grams: 430313.62500000047\n",
            "Perplexity for 2-grams: 382283.0000000003\n",
            "Perplexity for 3-grams: 382269.0000000001\n",
            "Perplexity for 4-grams: 382269.0000000001\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.lm import Laplace\n",
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "import random\n",
        "\n",
        "# Assuming 'text' is already tokenized, split it into words\n",
        "words = text.split()\n",
        "\n",
        "# Split the data into training and test sets\n",
        "train_size = int(0.8 * len(words))\n",
        "train_data = words[:train_size]\n",
        "test_data = words[train_size:]\n",
        "\n",
        "# Function to train an n-gram language model with Laplace smoothing\n",
        "def train_ngram_model(data, n):\n",
        "    ngram_model = Laplace(n)\n",
        "    ngram_model.fit([ngrams(data, n)], vocabulary_text=data)\n",
        "    return ngram_model\n",
        "\n",
        "# Function to calculate perplexity on a test set\n",
        "def calculate_perplexity(model, test_set, n):\n",
        "    perplexity = model.perplexity(test_set)\n",
        "    print(f\"Perplexity for {n}-grams: {perplexity}\")\n",
        "\n",
        "# Train unigram, bigram, trigram, and quadgram language models with Laplace smoothing\n",
        "unigram_model = train_ngram_model(train_data, 1)\n",
        "bigram_model = train_ngram_model(train_data, 2)\n",
        "trigram_model = train_ngram_model(train_data, 3)\n",
        "quadgram_model = train_ngram_model(train_data, 4)\n",
        "\n",
        "# Choose a random n-gram from the test set for evaluation\n",
        "random_test_ngram_unigram = random.choice(list(ngrams(test_data, 1)))\n",
        "random_test_ngram_bigram = random.choice(list(ngrams(test_data, 2)))\n",
        "random_test_ngram_trigram = random.choice(list(ngrams(test_data, 3)))\n",
        "random_test_ngram_quadgram = random.choice(list(ngrams(test_data, 4)))\n",
        "\n",
        "# Calculate perplexity for the random n-grams using the respective models\n",
        "calculate_perplexity(unigram_model, [random_test_ngram_unigram], 1)\n",
        "calculate_perplexity(bigram_model, [random_test_ngram_bigram], 2)\n",
        "calculate_perplexity(trigram_model, [random_test_ngram_trigram], 3)\n",
        "calculate_perplexity(quadgram_model, [random_test_ngram_quadgram], 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The code trains n-gram language models (unigram, bigram, trigram,  quadgram) and assesses their perplexity on a test set. Perplexity serves as a metric for evaluating how well the models predict unseen data, with lower values indicating better performance.\n",
        "#### Notably, as the n-gram order increases, perplexity tends to decrease, reflecting improved modeling of language dependencies. This intrinsic evaluation method provides insights into the models' ability to understand and predict patterns within the training data."
      ],
      "metadata": {
        "id": "Z5vZriVRuNsR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnhpNcUvR6mc"
      },
      "source": [
        "## 3. Evaluate these Language Models Using Extrinsic Evaluation Method"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "class NGramModel:\n",
        "    def __init__(self, ngram, text):\n",
        "        self.ngram = ngram\n",
        "        self.text = text\n",
        "        self.ngrams = self.generate_ngrams()\n",
        "        self.model = self.train_model()\n",
        "\n",
        "    def generate_ngrams(self):\n",
        "        words = [word for word in self.text.split()]\n",
        "        return zip(*[words[i:] for i in range(0, self.ngram)])\n",
        "\n",
        "    def train_model(self):\n",
        "        model = defaultdict(list)\n",
        "        for ngram in self.ngrams:\n",
        "            prefix = ' '.join(ngram[:-1])\n",
        "            suffix = ngram[-1]\n",
        "            model[prefix].append(suffix)\n",
        "        return model\n",
        "\n",
        "    def generate_next_word(self, prefix):\n",
        "        if prefix in self.model:\n",
        "            predicted_word = random.choice(self.model[prefix])\n",
        "        else:\n",
        "            # If prefix not found, return a random word from the training data\n",
        "            predicted_word = random.choice(self.text.split())\n",
        "        return predicted_word\n",
        "\n",
        "    def generate_text_completion(self, seed_text, max_length=50):\n",
        "        current_text = seed_text\n",
        "        for _ in range(max_length):\n",
        "            prefix = ' '.join(current_text.split()[-(self.ngram - 1):])\n",
        "            next_word = self.generate_next_word(prefix)\n",
        "            current_text += ' ' + next_word\n",
        "        return current_text, next_word\n",
        "\n",
        "# Read the text from the file\n",
        "text = open(\"tokenized.txt\", \"r\", encoding='utf-8', errors='replace').read()\n",
        "\n",
        "# Create a common input\n",
        "input_prefix = \"ከአብዮቱ ዘመን በኋላ\"\n",
        "\n",
        "# Create models for different n-grams\n",
        "unigram_model = NGramModel(1, text)\n",
        "bigram_model = NGramModel(2, text)\n",
        "trigram_model = NGramModel(3, text)\n",
        "quadgram_model = NGramModel(4, text)\n",
        "\n",
        "# Generate predictions or complete text for each model using the common input\n",
        "unigram_result = unigram_model.generate_text_completion(input_prefix)\n",
        "bigram_result = bigram_model.generate_text_completion(input_prefix)\n",
        "trigram_result = trigram_model.generate_text_completion(input_prefix)\n",
        "quadgram_result = quadgram_model.generate_text_completion(input_prefix)\n",
        "\n",
        "# Print the results\n",
        "print(\"Unigram Prediction:\", unigram_result[1], \"\\nGenerated Text:\", input_prefix + ' ' + unigram_result[1])\n",
        "print(\"\\nBigram Prediction:\", bigram_result[1], \"\\nGenerated Text:\", input_prefix + ' ' + bigram_result[1])\n",
        "print(\"\\nTrigram Prediction:\", trigram_result[1], \"\\nGenerated Text:\", input_prefix + ' ' + trigram_result[1])\n",
        "print(\"\\nQuadgram Prediction:\", quadgram_result[1], \"\\nGenerated Text:\", input_prefix + ' ' + quadgram_result[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cif1H1tueunr",
        "outputId": "0bb41734-9cf7-41b4-b164-6e1c21ee9735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Prediction: ለማሰባሰብ \n",
            "Generated Text: ከአብዮቱ ዘመን በኋላ ለማሰባሰብ\n",
            "\n",
            "Bigram Prediction: ታውቋል \n",
            "Generated Text: ከአብዮቱ ዘመን በኋላ ታውቋል\n",
            "\n",
            "Trigram Prediction: ጭፍን \n",
            "Generated Text: ከአብዮቱ ዘመን በኋላ ጭፍን\n",
            "\n",
            "Quadgram Prediction: ማንንም \n",
            "Generated Text: ከአብዮቱ ዘመን በኋላ ማንንም\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The provided code implements n-gram language models (unigram, bigram, trigram, and quadgram) for predicting the next word or completing text based on input prefixes. Extrinsic evaluation involves assessing these models in real-world applications, such as natural language processing tasks. By generating text predictions and completions, the models can be evaluated based on their coherence, contextual relevance, and overall effectiveness in enhancing language understanding and generation in practical scenarios."
      ],
      "metadata": {
        "id": "isWfF_l4oQkE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vZo51J3_odCv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "14S7aoVPZqmES-M8JEb4NSLT-Vgd13hLh",
      "authorship_tag": "ABX9TyODFBlr75+JHjJuLTC/uedW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}